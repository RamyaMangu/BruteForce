{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2245a61",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9ef7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mangu\\AppData\\Local\\Temp\\ipykernel_22800\\1802624429.py:49: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['processed'] = df['processed'].str.replace('http[^\\s]*',\"\")\n",
      "C:\\Users\\mangu\\AppData\\Local\\Temp\\ipykernel_22800\\1802624429.py:73: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['processed'] = df['processed'] .str.replace('[...‚Ä¶]','').str.split().apply(lambda x: ' '.join([replacers.get(e, e) for e in x]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "%run ./src/Preprocess.ipynb\n",
    "import tweepy\n",
    "import pickle\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558ee5d",
   "metadata": {},
   "source": [
    "# Application on the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2053e39",
   "metadata": {},
   "source": [
    "Rain Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7941b94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mangu\\AppData\\Local\\Temp\\ipykernel_22800\\1802624429.py:49: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['processed'] = df['processed'].str.replace('http[^\\s]*',\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Content vs Processed Text---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mangu\\AppData\\Local\\Temp\\ipykernel_22800\\1802624429.py:73: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['processed'] = df['processed'] .str.replace('[...‚Ä¶]','').str.split().apply(lambda x: ' '.join([replacers.get(e, e) for e in x]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rainy Memories‚Ä¶„Éâ„É©„Çπ„ÇøÂ•Ω„Åç„Åô„Åé„Å¶ÁãÇ„Å£„Å¶„Åó„Åæ„ÅÑ„Åù„ÅÜ‚Ä¶</td>\n",
       "      <td>rainy memories dorasutaHao kisugiteKuang tsute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stan Crap-\"Rainy days\" https://t.co/G5wahjDdlh...</td>\n",
       "      <td>stan crap rainy days ikebo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rainy dayyy</td>\n",
       "      <td>rainy dayyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Rainy_081495 „Åæ„ÅüÁ∂∫È∫ó„Å´„Å™„Çã„ÅÆ„Åß„Åô„Å≠</td>\n",
       "      <td>mataQi Li ninarunodesune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rainy morning ft. Abdulmajeed hits different</td>\n",
       "      <td>rainy morning ft abdulmajeed hits different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Rainy Day ü´∂üèªü§ç</td>\n",
       "      <td>rainy day emoji modifier fitzpatrick type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>It‚Äôs more rainy days than sunny but I smile th...</td>\n",
       "      <td>it is more rainy days than sunny but i smile t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Happy Rainy Day \\n        üåß ‚òïÔ∏è üåß</td>\n",
       "      <td>happy rainy day cloud with rain coffee cloud w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[ #paintings ] üñºÔ∏è\\n#PontAlexandreIII by Mitro....</td>\n",
       "      <td>paintings frame with picture pontalexandreiii ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>and to the rest of y'all, I seriously cannot t...</td>\n",
       "      <td>and to the rest of you all i seriously cannot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "0                   Rainy Memories‚Ä¶„Éâ„É©„Çπ„ÇøÂ•Ω„Åç„Åô„Åé„Å¶ÁãÇ„Å£„Å¶„Åó„Åæ„ÅÑ„Åù„ÅÜ‚Ä¶   \n",
       "1   Stan Crap-\"Rainy days\" https://t.co/G5wahjDdlh...   \n",
       "2                                         rainy dayyy   \n",
       "3                           @Rainy_081495 „Åæ„ÅüÁ∂∫È∫ó„Å´„Å™„Çã„ÅÆ„Åß„Åô„Å≠   \n",
       "4        Rainy morning ft. Abdulmajeed hits different   \n",
       "..                                                ...   \n",
       "92                                      Rainy Day ü´∂üèªü§ç   \n",
       "93  It‚Äôs more rainy days than sunny but I smile th...   \n",
       "94                   Happy Rainy Day \\n        üåß ‚òïÔ∏è üåß   \n",
       "95  [ #paintings ] üñºÔ∏è\\n#PontAlexandreIII by Mitro....   \n",
       "96  and to the rest of y'all, I seriously cannot t...   \n",
       "\n",
       "                                            processed  \n",
       "0   rainy memories dorasutaHao kisugiteKuang tsute...  \n",
       "1                          stan crap rainy days ikebo  \n",
       "2                                         rainy dayyy  \n",
       "3                            mataQi Li ninarunodesune  \n",
       "4         rainy morning ft abdulmajeed hits different  \n",
       "..                                                ...  \n",
       "92          rainy day emoji modifier fitzpatrick type  \n",
       "93  it is more rainy days than sunny but i smile t...  \n",
       "94  happy rainy day cloud with rain coffee cloud w...  \n",
       "95  paintings frame with picture pontalexandreiii ...  \n",
       "96  and to the rest of you all i seriously cannot ...  \n",
       "\n",
       "[97 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the saved model\n",
    "model = load_model('./src/model.h5')\n",
    "\n",
    "#Connecting to the Twitter API to extract the tweets\n",
    "client = tweepy.Client(bearer_token='AAAAAAAAAAAAAAAAAAAAAHiaigEAAAAA1hzpI79DUjAi9q8PvGD7lfTzWjQ%3Dw9PNTdJGBWQOWxJjY9l5yP1Z7fglAF5SQGbLN6LrzUHQ5Gvbkd')\n",
    "\n",
    "#Getting the tweets related to a speicifc topic\n",
    "#For the now I am extracting the tweets related to the hashtag rainy\n",
    "# -is:retweet means we don't want retweets\n",
    "query = 'rainy -is:retweet'\n",
    "tweets = client.search_recent_tweets(query = query, tweet_fields=['context_annotations', 'created_at'], max_results=100)\n",
    "tweet_lst = [tweet.text for tweet in tweets.data]\n",
    "\n",
    "#Labelling the text column to content and converting it into a dataframe\n",
    "data = {'content': tweet_lst}\n",
    "tweet_df = DataFrame(data)\n",
    "tweet_pro = preprocess(tweet_df)\n",
    "\n",
    "print(\"-----------Content vs Processed Text---------------\")\n",
    "tweet_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92c7a2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 170ms/step\n",
      "----------------------Results-----------------------------\n",
      "happiness: 28.77480387687683\n",
      "neutral: 43.718576431274414\n",
      "sadness: 27.50663459300995\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the input tweets, converting the labels and padding the texts\n",
    "x_dat = tweet_pro['processed']\n",
    "x_seq = tokenizer.texts_to_sequences(x_dat)\n",
    "x_data = pad_sequences(x_seq, maxlen = 34, padding='post')\n",
    "\n",
    "#Predicting the emotions based on the saved model\n",
    "y_pred = model.predict(x_data)\n",
    "\n",
    "#Using the encoder file we saved which consists of the labels, we ouput the predictions with their respective labels\n",
    "with open('encoder', 'rb') as file:\n",
    "    encoder = pickle.load(file)\n",
    "print(\"----------------------Results-----------------------------\")\n",
    "for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "    print(encoder.classes_[index] + \": \" + str(value * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744e398",
   "metadata": {},
   "source": [
    "petday Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e27cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Content vs Processed Text---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mangu\\AppData\\Local\\Temp\\ipykernel_22800\\1802624429.py:49: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['processed'] = df['processed'].str.replace('http[^\\s]*',\"\")\n",
      "C:\\Users\\mangu\\AppData\\Local\\Temp\\ipykernel_22800\\1802624429.py:73: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['processed'] = df['processed'] .str.replace('[...‚Ä¶]','').str.split().apply(lambda x: ' '.join([replacers.get(e, e) for e in x]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@slvppy Petday</td>\n",
       "      <td>petday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@cainasleeps @joao petday kkkkkkkk</td>\n",
       "      <td>petday kkkkkkkk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://t.co/bVdWNjfMI6\\n\\nI made a comic!\\n‚ö†Ô∏è...</td>\n",
       "      <td>i made a comic warningwarning profanity and vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üì∑ petday: kremlings https://t.co/dRowuZ3Osa</td>\n",
       "      <td>camera petday kremlings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The holidays are here be sure to checkout the ...</td>\n",
       "      <td>the holidays are here be sure to checkout the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Checkout these 4 piece protection antiskid pup...</td>\n",
       "      <td>checkout these piece protection antiskid puppy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#Affirmation I love petting my EGO when i MATU...</td>\n",
       "      <td>affirmation i love petting my ego when i matur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>It‚Äôs official announcement. My couch wolf didn...</td>\n",
       "      <td>it is official announcement my couch wolf did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hey guys, congratulations on World Pet Day. ü•∞ü•≥...</td>\n",
       "      <td>hey guys congratulations on world pet day smil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pero luego pienso que hoy es el PetDay en mi o...</td>\n",
       "      <td>pero luego pienso que hoy es el petday en mi o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Whether you have a dog, a cat or both it impor...</td>\n",
       "      <td>whether you have a dog a cat or both it import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Domingo √© dia de passear com o seu Pet no #Pet...</td>\n",
       "      <td>domingo e dia de passear com o seu pet no petday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "0                                      @slvppy Petday   \n",
       "1                  @cainasleeps @joao petday kkkkkkkk   \n",
       "2   https://t.co/bVdWNjfMI6\\n\\nI made a comic!\\n‚ö†Ô∏è...   \n",
       "3         üì∑ petday: kremlings https://t.co/dRowuZ3Osa   \n",
       "4   The holidays are here be sure to checkout the ...   \n",
       "5   Checkout these 4 piece protection antiskid pup...   \n",
       "6   #Affirmation I love petting my EGO when i MATU...   \n",
       "7   It‚Äôs official announcement. My couch wolf didn...   \n",
       "8   Hey guys, congratulations on World Pet Day. ü•∞ü•≥...   \n",
       "9   Pero luego pienso que hoy es el PetDay en mi o...   \n",
       "10  Whether you have a dog, a cat or both it impor...   \n",
       "11  Domingo √© dia de passear com o seu Pet no #Pet...   \n",
       "\n",
       "                                            processed  \n",
       "0                                              petday  \n",
       "1                                     petday kkkkkkkk  \n",
       "2   i made a comic warningwarning profanity and vi...  \n",
       "3                             camera petday kremlings  \n",
       "4   the holidays are here be sure to checkout the ...  \n",
       "5   checkout these piece protection antiskid puppy...  \n",
       "6   affirmation i love petting my ego when i matur...  \n",
       "7   it is official announcement my couch wolf did ...  \n",
       "8   hey guys congratulations on world pet day smil...  \n",
       "9   pero luego pienso que hoy es el petday en mi o...  \n",
       "10  whether you have a dog a cat or both it import...  \n",
       "11   domingo e dia de passear com o seu pet no petday  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the tweets related to a speicifc topic\n",
    "#For the now I am extracting the tweets related to the hashtag rainy\n",
    "# -is:retweet means we don't want retweets\n",
    "query = 'petday -is:retweet'\n",
    "tweets = client.search_recent_tweets(query = query, tweet_fields=['context_annotations', 'created_at'], max_results=100)\n",
    "tweet_lst = [tweet.text for tweet in tweets.data]\n",
    "\n",
    "#Labelling the text column to content and converting it into a dataframe\n",
    "data = {'content': tweet_lst}\n",
    "tweet_df = DataFrame(data)\n",
    "tweet_pro = preprocess(tweet_df)\n",
    "\n",
    "print(\"-----------Content vs Processed Text---------------\")\n",
    "tweet_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa6d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "----------------------Results-----------------------------\n",
      "happiness: 19.09622550010681\n",
      "neutral: 51.01444721221924\n",
      "sadness: 29.88932728767395\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the input tweets, converting the labels and padding the texts\n",
    "x_dat = tweet_pro['processed']\n",
    "x_seq = tokenizer.texts_to_sequences(x_dat)\n",
    "x_data = pad_sequences(x_seq, maxlen = 34, padding='post')\n",
    "\n",
    "#Predicting the emotions based on the saved model\n",
    "y_pred = model.predict(x_data)\n",
    "\n",
    "#Using the encoder file we saved which consists of the labels, we ouput the predictions with their respective labels\n",
    "with open('encoder', 'rb') as file:\n",
    "    encoder = pickle.load(file)\n",
    "print(\"----------------------Results-----------------------------\")\n",
    "for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "    print(encoder.classes_[index] + \": \" + str(value * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb08d97",
   "metadata": {},
   "source": [
    "Sunday Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e538665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Content vs Processed Text---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mangu\\AppData\\Local\\Temp\\ipykernel_19112\\1802624429.py:49: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['processed'] = df['processed'].str.replace('http[^\\s]*',\"\")\n",
      "C:\\Users\\mangu\\AppData\\Local\\Temp\\ipykernel_19112\\1802624429.py:73: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['processed'] = df['processed'] .str.replace('[...‚Ä¶]','').str.split().apply(lambda x: ' '.join([replacers.get(e, e) for e in x]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RTFKT COMEBACK?? #ETH #RTFKT @CioTheGemini @Cr...</td>\n",
       "      <td>rtfkt comeback eth rtfkt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Power Rankings: OSU up, UConn down after topsy...</td>\n",
       "      <td>power rankings osu up uconn down after topsy t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NP No Advise Me @iamorezi\\n\\n#BlastRise with @...</td>\n",
       "      <td>np no advise me blastrise with and a blast mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sana talaga lumaban internet ko sa Sunday üò≠üò≠üò≠</td>\n",
       "      <td>sana talaga lumaban internet ko sa sunday sobsob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Harvest22 ramped up last week with growers de...</td>\n",
       "      <td>harvest ramped up last week with growers deliv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I‚Äôll never forget this nigga dropping me off l...</td>\n",
       "      <td>i will never forget this nigga dropping me off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>It's been days since we have logged a ticket a...</td>\n",
       "      <td>it is been days since we have logged a ticket ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SYDNEY's Sunday Vibes: Gathering in the Park, ...</td>\n",
       "      <td>sydney s sunday vibes gathering in the park ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MARKET MANTRA 99 - STOCK / COMMODITY MARKET TR...</td>\n",
       "      <td>market mantra stock commodity market training ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Now Playing Var Don - Lazy Sunday Tune in now!...</td>\n",
       "      <td>now playing var don lazy sunday tune in now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "0   RTFKT COMEBACK?? #ETH #RTFKT @CioTheGemini @Cr...   \n",
       "1   Power Rankings: OSU up, UConn down after topsy...   \n",
       "2   NP No Advise Me @iamorezi\\n\\n#BlastRise with @...   \n",
       "3       sana talaga lumaban internet ko sa Sunday üò≠üò≠üò≠   \n",
       "4   #Harvest22 ramped up last week with growers de...   \n",
       "..                                                ...   \n",
       "95  I‚Äôll never forget this nigga dropping me off l...   \n",
       "96  It's been days since we have logged a ticket a...   \n",
       "97  SYDNEY's Sunday Vibes: Gathering in the Park, ...   \n",
       "98  MARKET MANTRA 99 - STOCK / COMMODITY MARKET TR...   \n",
       "99  Now Playing Var Don - Lazy Sunday Tune in now!...   \n",
       "\n",
       "                                            processed  \n",
       "0                            rtfkt comeback eth rtfkt  \n",
       "1   power rankings osu up uconn down after topsy t...  \n",
       "2   np no advise me blastrise with and a blast mor...  \n",
       "3    sana talaga lumaban internet ko sa sunday sobsob  \n",
       "4   harvest ramped up last week with growers deliv...  \n",
       "..                                                ...  \n",
       "95  i will never forget this nigga dropping me off...  \n",
       "96  it is been days since we have logged a ticket ...  \n",
       "97  sydney s sunday vibes gathering in the park ru...  \n",
       "98  market mantra stock commodity market training ...  \n",
       "99        now playing var don lazy sunday tune in now  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the tweets related to a speicifc topic\n",
    "#For the now I am extracting the tweets related to the hashtag rainy\n",
    "# -is:retweet means we don't want retweets\n",
    "query = 'sunday -is:retweet'\n",
    "tweets = client.search_recent_tweets(query = query, tweet_fields=['context_annotations', 'created_at'], max_results=100)\n",
    "tweet_lst = [tweet.text for tweet in tweets.data]\n",
    "\n",
    "#Labelling the text column to content and converting it into a dataframe\n",
    "data = {'content': tweet_lst}\n",
    "tweet_df = DataFrame(data)\n",
    "tweet_pro = preprocess(tweet_df)\n",
    "\n",
    "print(\"-----------Content vs Processed Text---------------\")\n",
    "tweet_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e63790a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 140ms/step\n",
      "----------------------Results-----------------------------\n",
      "happiness: 32.18759596347809\n",
      "neutral: 43.63190531730652\n",
      "sadness: 24.180492758750916\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the input tweets, converting the labels and padding the texts\n",
    "x_dat = tweet_pro['processed']\n",
    "x_seq = tokenizer.texts_to_sequences(x_dat)\n",
    "x_data = pad_sequences(x_seq, maxlen = 34, padding='post')\n",
    "\n",
    "#Predicting the emotions based on the saved model\n",
    "y_pred = model.predict(x_data)\n",
    "\n",
    "#Using the encoder file we saved which consists of the labels, we ouput the predictions with their respective labels\n",
    "with open('encoder', 'rb') as file:\n",
    "    encoder = pickle.load(file)\n",
    "print(\"----------------------Results-----------------------------\")\n",
    "for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "    print(encoder.classes_[index] + \": \" + str(value * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
